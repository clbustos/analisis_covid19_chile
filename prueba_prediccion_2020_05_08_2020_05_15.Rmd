---
title: "Prueba modelo predictivo (8 de Mayo a 15 de Mayo)"
output:
  html_document:
    theme: lumen
    df_print: paged
editor_options:
  chunk_output_type: inline
---
```{r setup,echo=F, include=FALSE}
source("analisis_3.R")
library(ggplot2)
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)
f.inicial <- 43958
f.final   <- 43965
```

Todo modelo predictivo debe probarse con datos reales, para determinar su validez. Una forma de medir el grado de error es el error medio cuadrático, que se calcula

$$ 
EMC= \sum_i^k \frac{(y_i-\hat{y_i})^2}{n}
$$

Donde $y_i$ es el dato observado en el momento $i$, en tanto que $\hat{y_i}$ es valor predicho. En nuestros ejemplos, como se calculará el EMC sobre los valores al logaritmo.

Durante esta semana, se probó un modelo cuadrático sobre los datos en bruto, con una estructura de autocorrelación AR(2).

## Modelos de casos totales


Probaremos la adecuación de los tres modelos, que usamos hasta el momento - general cuadrático + AR(1), casos nuevos + AR(1), casos nuevos + AR(4), usando el modelo calculado el día [8 de Mayo](https://rpubs.com/clbustos/611478). 

Se debe considerar que como los reportes del MINSAL se realizan con un día de retraso, realmente estamos usando los datos del día 7 de Mayo para predecir hasta el 14.

```{r}
data.frame(inicio=convertToDate(f.inicial),
           final=convertToDate(f.final))
```


A diferencia de la prueba anterior del modelo, el modelo cuadrático ha funcionado bastante mal, estando fuera del intervalo de confianza 4 de los 7 días. El modelo de T+AR(1), muy similar al cuadrático, al menos mantiene el intervalo de confianza. El modelo T+AR(4) funcionó muy bien los primeros 4 días, hasta el aumento repentino de casos los últimos 3 días, pero igual se mantiene el intervalo de confianza.  

```{r}
calcular.mse<-function(x,y) {
  mean((log(x$casos)-log(y$casos))^2)
}



dato.a.inicial<-datos.casos$total[datos.casos$total$fecha <= f.inicial,]
dato.a.final<-datos.casos$total[datos.casos$total$fecha   <= f.final,]

obtener.prediccion<-function(x.comp,min.casos, n.ahead=7) {
  n.comp<-nrow(x.comp)
  x.parc<-x.comp[1:(n.comp-n.ahead), ]
  
  dato.obs<-data.frame(
    dia=x.comp$dia,
    casos=x.comp$casos,
    li=x.comp$casos, 
    ls=x.comp$casos,
    tipo="Observado",
    pais="Chile"
)
  prediccion<-prediccion.casos(list(Chile=x.parc),min.casos = min.casos, modelos = c("tar2", "tar4","cuad"),n.ahead = n.ahead)
  out<-list()
  out$dato.obs<-dato.obs
  out$dato.obs.parc<-tail(x.comp,n.ahead)
  out$p.tar21<-tail(prediccion$tar2$Chile,n.ahead)
  out$p.tar4 <-tail(prediccion$tar4$Chile,n.ahead)
  out$p.cuad<-tail(prediccion$cuad$Chile,n.ahead)
  out$para.ver<-rbind(out$dato.obs, out$p.tar21,out$p.tar4,out$p.cuad)
  
  out
}

pred.50<-obtener.prediccion(dato.a.final, 50)
max.x<-max(pred.50$para.ver$dia)
max.y<-max(pred.50$para.ver$casos)

ggplot(pred.50$para.ver, aes(x=dia, y=casos, color=tipo, ymin=li, ymax=ls))+geom_point()+geom_line()+geom_ribbon(alpha=0.1)+geom_hline(yintercept = 50)+scale_y_continuous(trans="log10",limits = c(max.y-max.y/2, max.y+max.y/2))+xlim(max.x-10,max.x+2)
```

El MSE de T+AR(4) es menor al de T+AR(1) y el modelo cuadrático, lo contrario a lo que ocurrió en la prueba anterior.

```{r}
data.frame("T+AR(1)"=calcular.mse(pred.50$dato.obs.parc, pred.50$p.tar21),
           "T+AR(4)"=calcular.mse(pred.50$dato.obs.parc, pred.50$p.tar4),
           "Cuadrático"=calcular.mse(pred.50$dato.obs.parc, pred.50$p.cuad)
           )

```


¿Qué pasaría si hubiesemos considerado solo desde el caso 250 en adelante, como hace un mes? Se puede ver que tanto T+AR(1) y T+AR(4) se habrían comportado bien, mientras el modelo cuadrático habría subestimado todo el tiempo.



```{r}

pred.250<-obtener.prediccion(dato.a.final, 250)
max.x<-max(pred.250$para.ver$dia)
max.y<-max(pred.250$para.ver$casos)

ggplot(pred.250$para.ver, aes(x=dia, y=casos, color=tipo, ymin=li,ymax=ls))+geom_point()+geom_line()+geom_ribbon(alpha=0.1)+geom_hline(yintercept = 250) + scale_y_continuous(trans="log10",limits = c(max.y-max.y/2, max.y+max.y/2))+xlim(max.x-10, max.x+2)

```

Bajo este enfoque, T+AR(4) funciona muy bien, prácticamente con la mitad del error de mantener desde los 50 casos. T+AR(1) tiene un error similar al de mantener 50 casos, en tanto que el cuadrático mantiene su error.

```{r}
data.frame("T+AR(1)"=calcular.mse(pred.250$dato.obs.parc, pred.250$p.tar21),
           "T+AR(4)"=calcular.mse(pred.250$dato.obs.parc, pred.250$p.tar4),
           "Cuadrático"=calcular.mse(pred.250$dato.obs.parc, pred.50$p.cuad)
           )

```

Si utilizamos el corte del periodo anterior, con 20 casos, el modelo T+AR(4) nuevamente funciona bastante bien, en tanto que T+AR(1) y el cuadrático subestiman de forma sistemática.

```{r}

pred.20<-obtener.prediccion(dato.a.final, 20)
max.x<-max(pred.20$para.ver$dia)
max.y<-max(pred.20$para.ver$casos)

ggplot(pred.20$para.ver, aes(x=dia, y=casos, color=tipo, ymin=li,ymax=ls))+geom_point()+geom_line()+geom_ribbon(alpha=0.1)+geom_hline(yintercept = 20) + scale_y_continuous(trans="log10",limits = c(max.y-max.y/2, max.y+max.y/2))+xlim(max.x-10, max.x+2)
```

Los errores son mayores a los de cortar a los 50 o 250 casos.

```{r}
data.frame("T+AR(1)"=calcular.mse(pred.20$dato.obs.parc, pred.20$p.tar21),
           "T+AR(4)"=calcular.mse(pred.20$dato.obs.parc, pred.20$p.tar4),
           "Cuadrático"=calcular.mse(pred.20$dato.obs.parc, pred.20$p.cuad)
           )

```


## Predicción por regiones

Durante las últimas semanas hemos probado un modelo de predicción que suma los resultados parciales por región. Para cada región se elige un punto de corte distinto, el cual se puede consultar en el código a continuación

```{r}
min.corte<-list(
    "Arica.y.Parinacota"=10,
    "Tarapacá"=10,
    "Antofagasta"=10,
    "Atacama"=2,
    "Coquimbo"=10,
    "Valparaíso"=10,
    "Metropolitana"=50,
    "O’Higgins"=10,
    "Maule"=10,
    "Ñuble"=20,
    "Biobío"=10,
    "Araucanía"=10,
    "Los.Ríos"=20,
    "Los.Lagos"=20,
    "Aysén"=2,
    "Magallanes"=10)

dc.inicio<-lapply(datos.casos,function(x) {x[x$fecha<=f.inicial,]})
dc.final<-lapply(datos.casos,function(x) {x[x$fecha<=f.final,]})

ppz.inic<-prediccion.por.zonas(min.corte,dc.inicio,n.ahead = 7, modelos = c("tar2","cuad"))
obs<-dato.a.final[dato.a.final$fecha>=f.inicial+1 & dato.a.final$fecha<=f.final,]

max.x<-max(obs$dia)
max.y<-max(obs$casos)


```

Se observamos la serie posterior, con detalle, podemos ver que AR(1) tiene un ajuste muy bueno a los datos, en tanto que el modelo exponencial tiende, a subestimar.
```{r}
ggplot(rbind(ppz.inic, data.frame(tipo="observado",obs[,c("dia","fecha","casos")])), aes(x=dia,y=casos, color=tipo))+geom_line()+ scale_y_continuous(trans="log10",limits = c(max.y-max.y/2, max.y+max.y/2))+xlim(max.x-10, max.x+2)
```

El MSE del TAR regional es extremadamente bueno, y el modelo lineal cuadrático, si bien un poco  inferior,sigue superando en dos órdenes de magnitud la predicción del modelo general.
```{r}

data.frame("Suma regional T+AR(1)"=calcular.mse( obs, ppz.inic[ppz.inic$tipo=="Casos nuevo: Tendencia + AR(1)",]),
           "Suma regional Lineal cuadrático"=calcular.mse(obs, ppz.inic[ppz.inic$tipo=="General: Cuadrático + AR(1)",])
           )
```



## Conclusión

Tras 3 evaluaciones de modelos, destaca la ventaja de tener varios algoritmos, ya que algunos funcionan mejor cuando el proceso no experimenta cambios bruscos (cuadrático), en cambio otros no siempre son óptimos por semana, pero aparecen como buenas estrategias porque nunca son muy malos (T+AR(4)). El claro ganador es el modelo de suma regional, que en las dos últimas pruebas ha logrado acercarse mucho a la sumatoria total, lo que refleja la importancia de analizar los procesos a nivel local.