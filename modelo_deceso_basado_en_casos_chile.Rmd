---
title: "Modelo para decesos basado en casos, Covid 19 - Chile"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, include=FALSE}
source("funciones_soporte.R")
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)

library(ggplot2)
library(glmnet)

library(rms)
library(openxlsx)
library(dynlm)
chile.casos<-diff(c(0,read.xlsx("casos_chile_regiones.xlsx")$total))
chile.decesos<-diff(c(0, read.xlsx("casos_chile_regiones.xlsx",sheet = 2)$total))
chile<-data.frame(
  decesos=chile.decesos,
  casos.0=chile.casos
)
n<-nrow(chile)
  for(i in 1:22) {
    chile[[paste0("casos.",i)]]<-c(rep(0,i), chile.casos[1:(n-i)])
  }
```

```{r}
c1<-cor(chile)[1,-1]
colores<-numeric(length(c1))
colores[which.max(c1)]<-1

plot(0:22,c1 ,col=colores+1)
```

# Método 1: Modelo dinámico linear

Podemos hacer un modelo un poco bruto, en el cual modelamos el número de decesos actuales utilizando la cantidad de casos nuevos con lags de 0 a 14, más un autoregresivo sobre el mismo valor de decesos. Claramente, es un modelo sobreajustado.
```{r}
chile.casos.ts<-ts(chile.casos)
chile.decesos.ts<-ts(chile.decesos)
dyn1<-dynlm(chile.decesos.ts~L(chile.decesos.ts)+L(chile.casos.ts,0:14),chile)
summary(dyn1)
```

Si analizamos supuestos, vemos que la relación no es lineal, con un claro patrón en U de los residuos, y que hay un leve aumento de varianza en los valores altos predichos. También podemos observar que existen residuos importantes, en valores con alto leverage.
```{r}
plot(dyn1)
```

Si realizamos un análisis de validación con bootstrap, es muy claro el nivel de sobreajuste que tiene el modelo.
```{r}
x1<-dyn1$model
library(rms)
ols.1<-ols(chile.decesos.ts~.,x1,x=T,y=T)
validate(ols.1)
```


## Regularización

```{r}
xx<-as.matrix(x1)[,-1]
yy<-as.numeric(x1[,1])
cvfit<-cv.glmnet( xx,yy)
plot(cvfit)
```
Si observamos los coeficientes significativos, podemos ver que correponden al lag 1, otros cercanos a la semana y otros cercanos a las dos semanas.
```{r}
(coef.s0<-coef(cvfit, s="lambda.1se"))
```

El R²  es más bajo que el del modelo completo.
```{r}
pr1<-predict(cvfit, s="lambda.1se",newx = xx)
cor(pr1, yy)^2
```


El modelo tiene un problema similar al del saturado, con subestimación de valores bajos y altos.


```{r}
ggplot(data.frame(predicho=as.numeric(pr1),observado=yy), aes(x=predicho, y=observado))+geom_point()+geom_abline()+geom_smooth()+xlim(0,12)
```

Probemos a validar el modelo previo.El R² es mejor que el del modelo con múltiples  indicadores.


```{r}
coef.rel<-which(as.logical(coef.s0!=0))[-1]-1
xx.l<-data.frame(xx[,coef.rel],yy=yy)
ols.2<-ols(yy~., xx.l,x=T,y=T)
validate(ols.2)
```

## Modelo Poisson

Primero, probemos un modelo Poisson con todos los coeficientes
```{r}

pois.0<-glm(yy~xx ,chile,x=T,y=T,family="poisson")
summary(pois.0)
```
La predicción es bastante buena!

```{r}
ggplot(data.frame(pr=predict(pois.0,type="response"), obs=yy), aes(x=pr,y=obs))+geom_point()+geom_smooth()+geom_abline()

```

```{r}

pois.1<-glm(formula(paste0("decesos~",paste0("casos.",coef.rel-1, collapse=" + "))) ,chile,x=T,y=T,family="poisson")
summary(pois.1)
```
```{r}
cor(predict(pois.1,type="response"), chile$decesos)^2
```

  
```{r}
ggplot(data.frame(pr=predict(pois.1,type="response"), obs=chile$decesos), aes(x=pr,y=obs))+geom_point()+geom_smooth()+geom_abline()

```




